#!/bin/sh

YTFZF_VERSION="2.0_alpha"

# Scraping: query -> video json
# User Interface: video json -> user selection -> ID
# Player: ID -> video player

# error codes:
# 0: success
# 1: general error
# 2: invalid -opt or command argument, invalid argument for opt, configuration error
	# eg: ytfzf -c terminal (invalid scrape)
# 3: missing dependancy
# 4: scraping error

# colors {{{
c_red="\033[1;31m"
c_green="\033[1;32m"
c_yellow="\033[1;33m"
c_blue="\033[1;34m"
c_magenta="\033[1;35m"
c_cyan="\033[1;36m"
c_reset="\033[0m"
#}}}

# Utility functions {{{
dep_check() {
	command -v "$1" > /dev/null 2>&1
}

function_exists () {
	type "$1" > /dev/null 2>&1
}

#capitalizes the first letter of a string
title_str () {
	first_letter="$(printf "%s" "$1" | sed 's/\(.\).*/\1/' | tr '[:lower:]' '[:upper:]')"
	printf "%s" "$1" | sed 's/.\(.*\)/'"$first_letter"'\1/'
}

print_info () {
	# information goes to stdout ( does not disturb show_link_only )
	[ $log_level -ge 0 ] && printf "$1" >&2
}
print_warning () {
	[ $log_level -ge 1 ] && printf "${c_yellow}${1}${c_reset}" >&2
}
print_error () {
	[ $log_level -ge 2 ] && printf "${c_red}${1}${c_reset}" >&2
}

clean_up () {
	# print_info "cleaning up\n"
	# clean up only as parent process
	if [ "$YTFZF_PID" = "$$" ]; then
		[ -d "$session_cache_dir" ] && rm -r "$session_cache_dir"
	fi
}

die () {
	_return_status=$1
	print_error "$2"
	exit "$_return_status"
}

trim_id () {
	while IFS= read _line;do
		printf '%s\n' "${_line##*|}"
	done
}

search_is_empty () {
	case "$search" in
		-|'') return 0 ;;
	esac
	return 1
}

# Traps {{{
[ -z "$UEBERZUG_FIFO" ] && trap 'clean_up' EXIT
[ -z "$UEBERZUG_FIFO" ] && trap 'exit' INT TERM HUP
#}}}

# }}}

# Global Variables and Start Up {{{

# expansions where the variable is a string and globbing shouldn't happen should be surrounded by quotes
# variables that cannot be empty should use := instead of just =

#configuration handling {{{
: "${YTFZF_CONFIG_DIR:=$HOME/.config/ytfzf}"
: "${YTFZF_CONFIG_FILE:=$YTFZF_CONFIG_DIR/conf.sh}"
: "${YTFZF_SUBSCRIPTIONS_FILE:=$YTFZF_CONFIG_DIR/subscriptions}"

[ -f "$YTFZF_CONFIG_FILE" ] && . "$YTFZF_CONFIG_FILE"
#}}}

: ${useragent='Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.152 Safari/537.36'}

# menu options
#the menu to use instead of fzf when -D is specified
function_exists "external_menu" || external_menu () {
	dmenu -i -l 30 -p Search:
}

function_exists "search_prompt_menu" || search_prompt_menu () {
	if [ $is_ext_menu -eq 1 ]; then
		search="$(printf '' | external_menu)"
	else
		printf "Search: "
		read -r search
	fi
}

#number of columns (characters on a line) the external menu can have
: ${external_menu_len:=210}

: ${is_loop:=0}

# Players
function_exists "video_detach_player" || video_detach_player () {
	setsid -f mpv --ytdl-format="$video_pref" "$@" 1>/dev/null 2>&1
}
function_exists "video_player" || video_player () {
	mpv --ytdl-format="$video_pref" "$@"
}
function_exists "audio_player" || audio_player () {
	mpv --no-video "$@"
}
function_exists "downloader" || downloader () {
	case $is_audio_only in
	    0) ${ytdl_path:-youtube-dl} -f "${video_pref}" $ytdl_opts "$@"	;;
	    1) ${ytdl_path:-youtube-dl} -x $ytdl_opts "$@" ;;
	esac
}

# directories
: "${cache_dir:=$HOME/.cache/ytfzf}"

# files
: ${hist_file:=$cache_dir/watch_hist}

# history
: ${enable_hist=1}

# format options
#variable for switching on sort (date)
: ${is_detach:=0}
: ${is_audio_only:=0}
: ${is_download:=0}
: ${info_to_print=}
: ${exit_on_info_to_print:=1}
: ${video_pref=best}

: ${is_sort:=0}
: ${show_thumbnails:=0}
: ${is_ext_menu:=0}

: ${is_interface_scripting:=0}
: ${scripting_video_count:=1}
: ${is_random_select:=0}
: ${is_auto_select:=0}

# option parsing
: "${long_opt_char:=-}"

# scrape
: "${scrape=youtube}"
#this comes from invidious' api
: "${yt_thumbnail_quality=default}"
: ${sub_link_count:=10}
: "${invidious_instance:=ytprivate.com}"
: ${pages_to_scrape:=1}

: "${search_sort_by:=relevance}"
: "${search_upload_date=}"
: "${search_video_duration=}"
: "${search_result_type:=all}"
: "${search_result_features=}"
: "${search_region:=US}"

# debugging
: ${log_level:=2}

# Option Checks {{{
case "$long_opt_char" in
        [a-uw-zA-UW-Z0-9]) die 2 "long_opt_char must be v or non alphanumeric" ;;
	#? = 1 char, * = 1+ chars; ?* = 2+ chars
	??*) die 2 "long_opt_char must be 1 char" ;;
esac
#}}}

tab_space=$(printf '\t')
gap_space="                                                                   "

# }}}

usage () {
	printf "%s" \
"Usage: ytfzf [OPTIONS...] <search-query>
    If search-query is -, stdin will be read as the search query
    OPTIONS:
	-h			Show this help text
	-d			Download the selected video(s)
	-m			Only play audio
	-l                      Reopen the menu when the video stops playing
	-L			Show the link of selected video(s)
	-c <scraper>       	The scraper to use,
				Builtin scrapers:
				    youtube/Y, youtube-trending/T, youtube-subscriptions/S/SI,
				    peertube/P, odysee/lbry/O,
				    history/H
				    * SI scrapes invidious for channels instead of youtube,
				    * Y and T both scrape invidious
				you can use multiple scrapers by separating each with a , eg: youtube,odysee
	-t			Show thumbnails
	-D			Use an external menu
	-I <info>               Instead of playing the selected video(s), get information about them.
				Options can be separated with a comma, eg: L,R
	                        Options for info:
				    L:         print the link of the video
				    VJ:        print the json of the video
				    J:         print the json of all videos shown in the search
				    R:         print the data of the selected videos, as appears in the menu
				
"
}


# Scraping {{{
# * a scraper function takes a search query as $1 and returns video json to file $2
# * argument 3 and above are undefined and can be used for filters
# * return codes:
#            5 : scrape is disabled
#            6 : no response from site (matches curl)
#            22: error scraping site (matches curl)

# Json keys:
#	Needed:
#	ID url title
#	Optional:
#	thumbs channel duration views date description


## Youtube 
# Youtube backend functions {{{
_get_request () {
	_base_url=$1
	# Get search query from youtube
	curl -f "$_base_url" -s -L \
	  -H "User-Agent: $useragent" \
	  -H 'Accept-Language: en-US,en;q=0.9' \
	  --compressed
}


_youtube_channel_name () {
	# takes channel page html (stdin) and returns the channel name
	grep -o '<title>.*</title>' |
		sed \
		-e 's/ - YouTube//' \
		-e 's/<\/\?title>//g' \
		-e "s/&apos;/'/g" \
		-e "s/&#39;/'/g" \
		-e "s/&quot;/\"/g" \
		-e "s/&#34;/\"/g" \
		-e "s/&amp;/\&/g" \
		-e "s/&#38;/\&/g"
}

_youtube_get_json (){ 
       # Separates the json embedded in the youtube html page
       # * removes the content after ytInitialData
       # * removes all newlines and trims the json out
       sed -n '/var *ytInitialData/,$p' |
               tr -d '\n' |
               sed -E ' s_^.*var ytInitialData ?=__ ; s_;</script>.*__ ;'
}

_youtube_channel_json () {
	channel_name=$1
	jq '[ .contents | ..|.gridVideoRenderer? | select(. !=null) |
	    {
	    	ID: .videoId,
			url: "https://www.youtube.com/watch?v=\(.videoId)",
	    	title: .title.runs[0].text,
	    	channel: "'"$channel_name"'",
	    	thumbs: .thumbnail.thumbnails[0].url|sub("\\?.*";""),
	    	duration:.thumbnailOverlays[0].thumbnailOverlayTimeStatusRenderer.text.simpleText,
	    	views: .shortViewCountText.simpleText,
	    	date: .publishedTimeText.simpleText,
	    }
	]'
}
#}}}

scrape_youtube_channel () {
	channel_url="$1"
	output_json_file="$2"
	tmp_filename="$3"
	print_info "Scraping Youtube channel: $channel_url\n"
	_tmp_html="${session_temp_dir}/channel-$tmp_filename.html"
	_tmp_json="${session_temp_dir}/channel-$tmp_filename.json"

	# Converting channel title page url to channel video url
	case $channel_url in
		*featured) channel_url=${channel_url%featured}videos ;;
	esac

	_get_request "${channel_url##* }" "" "" > "$_tmp_html"
	_youtube_get_json < "$_tmp_html" > "$_tmp_json"

	channel_name=$(_youtube_channel_name < "$_tmp_html" )
	_youtube_channel_json "$channel_name" < "$_tmp_json"  >> "$output_json_file"
}
# }}} 

## Invidious {{{
# invidious backend functions {{{
_get_real_channel_link () {
	domain=${1#https://}
	domain=${domain%%/*}
	url=$(printf "%s" "$1" | sed "s/www.youtube.com/$invidious_instance/")
	real_path="$(curl -is "$url" | grep "^[lL]"ocation | sed 's/[Ll]ocation: //')"
	#prints the origional url because it was correct
	[ -z "$real_path" ] && printf "%s\n" "$1" && return 0
	#printf is not used because weird flushing? issues.
	echo "https://${domain}${real_path}"
}

_get_channel_id () {
	link="$1"
	link="${link##*channel/}"
	link="${link%/*}"
	printf "%s" "$link"
}


_invidious_thumb_quality_index () {
	_quality="$1"
	case "$_quality" in
		maxres) printf 0 ;;
		maxresdefault) printf 1 ;;
		sddefault) printf 2 ;;
		high) printf 3 ;;
		medium) printf 4 ;;
		default) printf 5 ;;
		start) printf 6 ;;
		middle) printf 7 ;;
		end) printf 8 ;;
	esac
	unset _quality
}

_invidious_search_json_playlist () {
	jq '[ .[] | select(.type=="playlist") |
		{
			ID: .playlistId,
			url: "https://www.youtube.com/playlist?list=\(.playlistId)",
			title: "[playlist] \(.title)",
			channel: .author,
			thumbs: .playlistThumbnail,
			duration: "\(.videoCount) videos",
		}
	]'
}
_invidious_search_json_live () {
	jq '[ .[] | select(.type=="video" and .liveNow==true) |
		{
			ID: .videoId,
			url: "https://'"${invidious_instance}"'/watch?v=\(.videoId)",
			title: "[live] \(.title)",
			channel: .author,
			thumbs: .videoThumbnails['"$_yt_thumbnail_quality_index"'].url ,
		}
	]'
}
_invidious_search_json_videos () {
	jq '[ .[] | select(.type=="video" and .liveNow==false) |
		{
			ID: .videoId,
			url: "https://'"${invidious_instance}"'/watch?v=\(.videoId)",
			title: .title,
			channel: .author,
			thumbs: .videoThumbnails['"$_yt_thumbnail_quality_index"'].url ,
			duration: "\(.lengthSeconds / 60 | floor):\(.lengthSeconds % 60)",
			views: "\(.viewCount)",
			date: .publishedText,
			description: .description
		}
	]'
}
_invidious_channel_json () {
	channel_name=$1
	jq '[ .latestVideos |.[] |
	    {
	    	ID: .videoId,
		url: "https://'"${invidious_instance}"'/watch?v=\(.videoId)",
	    	title: .title,
	    	channel: "'"$channel_name"'",
		thumbs: .videoThumbnails['"$_yt_thumbnail_quality_index"'].url ,
		duration: "\(.lengthSeconds / 60 | floor):\(.lengthSeconds % 60)",
		views: "\(.viewCount)",
		date: .publishedText,
		description: .description
	    }
	]'
}
#}}}

scrape_invidious_search () {
	page_query=$1
	output_json_file=$2
	pagetype=$3
	page_num=$4

	_tmp_json="${session_temp_dir}/yt-search-$page_num.json"

	_yt_thumbnail_quality_index="$(_invidious_thumb_quality_index "$yt_thumbnail_quality")"

	print_info "Scraping YouTube (with $invidious_instance) ($page_query, pg: $page_num)\n"

	_get_request "https://$invidious_instance/api/v1/search?q=$(printf "%s" "$page_query" | sed 's/ /%20/g')&type=${search_result_type}&sort_by=${search_sort_by}&date=${search_upload_date}&duration=${search_video_duration}&features=${search_result_features}&region=${search_region}&page=${page_num}" > "$_tmp_json"
	rv="$?"
	[ "$rv" -gt 0 ] && return $rv

	{
		_invidious_search_json_live < "$_tmp_json"
		_invidious_search_json_videos < "$_tmp_json"
		_invidious_search_json_playlist < "$_tmp_json"
	} >> "$output_json_file"
}

scrape_invidious_trending () {
	trending_tab=$(title_str $1)
	output_json_file=$2
	print_info "Scraping YouTube (with $invidious_instance) trending (${trending_tab:-Normal})\n"

	_tmp_json="${session_temp_dir}/yt-trending"

	_yt_thumbnail_quality_index="$(_invidious_thumb_quality_index "$yt_thumbnail_quality")"

	url="https://$invidious_instance/api/v1/trending"
	[ -n "$trending_tab" ] && url="${url}?type=${trending_tab}" && _tmp_json="${_tmp_json}-$trending_tab"

	_get_request "$url" > "$_tmp_json"
	rv="$?"
	[ "$rv" -gt 0 ] && return $rv

	_invidious_search_json_videos < "$_tmp_json" >> "$output_json_file"
}

scrape_invidious_channel () {
	channel_url=$1
	print_info "Scraping Youtube (with $invidious_instance) channel: $channel_url\n"
	output_json_file=$2
	tmp_file_name=$3

	# Converting channel title page url to channel video url
	printf "%s" "$channel_url" | grep -Eqv '/videos$' && channel_url="${channel_url}/videos"
	channel_id="$(_get_channel_id "$channel_url")"
	[ "$channel_id/videos" = "$channel_url" ] &&\
		print_warning "$channel_url is not a scrapable link run:\n$0 --channel-link='$channel_url'\nto fix this warning\n" &&\
		channel_url="$(_get_real_channel_link "$channel_url")" && channel_id="$(_get_channel_id "$channel_url")"

	#if this var isn't unique, weird things happen,
	_tmp_json="${session_temp_dir}/$tmp_file_name.json"
	channel_url="https://$invidious_instance/api/v1/channels/$channel_id"
	_get_request "${channel_url##* }" > "$_tmp_json"
	rv="$?"
	[ "$rv" -gt 0 ] && return $rv
	channel_name="$(jq '.author' < "$_tmp_json" | tr -d '"')"

	_invidious_channel_json "$channel_name" < "$_tmp_json"  >> "$output_json_file"
}
## }}}

## Peertube {{{
scrape_peertube () {
	page_query=$1
	output_json_file=$2
	print_info "Scraping Peertube ($page_query)\n"

	_tmp_json="${session_temp_dir}/peertube.json"

	#gets a list of videos
	curl -f -s "https://sepiasearch.org/api/v1/search/videos" \
	  -G --data-urlencode "search=$1" > "$_tmp_json"
	rv="$?"
	[ "$rv" -gt 0 ] && return $rv

	jq '[ .data | .[] |
			{
				ID: .uuid,
				url: .url,
				title: .name,
				channel: .channel.displayName,
				thumbs: .thumbnailUrl,
				duration: "\(.duration / 60 | floor):\(.duration % 60)",
				views: "\(.views)",
				date: .publishedAt
			}
		]' < "$_tmp_json" >> "$output_json_file"

}
## }}}

## Odysee {{{
scrape_odysee () {
	page_query=$1
	output_json_file=$2
	print_info "Scraping Odysee ($page_query)\n"

	_tmp_json="${session_temp_dir}/odysee.json"

	# TODO: filters
	curl \
	    -f -s "https://lighthouse.lbry.com/search" \
	    -G --data-urlencode "s=$page_query" \
	    --data-urlencode "mediaType=video,audio" \
	    --data-urlencode "include=channel,title,thumbnail_url,duration,cq_created_at,description,view_cnt" \
	    --data-urlencode "size=$odysee_video_search_count" > "$_tmp_json"

	rv="$?"
	[ "$rv" -gt 0 ] && return $rv

	jq '[ .[] |
	    {
			ID: .claimId,
			title: .title,
			url: "https://www.odysee.com/\(.channel)/\(.name)",
			channel: .channel,
			thumbs: .thumbnail_url,
			duration: "\(.duration / 60 | floor):\(.duration % 60)",
			views: "\(.view_cnt)",
			date: .cq_created_at
	    }
	]' < "$_tmp_json" >> "$output_json_file" 
	# TODO:  error handling 2 character

}
## }}}

# History{{{
scrape_history () {
	[ $enable_hist -eq 0 ] && print_info "enable_hist must be set to 1 for this option" && return 5
	output_json_file="$2"
	enable_hist=0 #enabling history while scrape is history causes issues
	cp "$hist_file" "$output_json_file" 2>/dev/null
}
#}}}

# }}}

# Sorting {{{

function_exists "get_sort_by" || get_sort_by () {
	line="$1"    
	date="${line%|*}"
	date=${date##*|}
	#youtube specific
	date=${date#*Streamed}
	date=${date#*Premiered}
	date -d "$date" '+%s' 2>/dev/null || date -f "$date" '+%s' 2> /dev/null || printf "null"
	unset line
}

function_exists "data_sort_fn" || data_sort_fn () {
	sort -nr
}

sort_video_data_fn () {
	if [ $is_sort -eq 1 ]; then
		while IFS= read -r line
		do
			#run the key function to get the value to sort by
			get_sort_by "$line" | tr -d '\n'
			printf "\t%s\n" "$line"
		done | data_sort_fn | cut -f2-
	else
		cat
	fi
}
#}}}

# History Management {{{
add_to_hist () {
	#id of the video to add to hist will be passed through stdin
	#if multiple videos are selected, multiple ids will be present on multiple lines
	while read -r id; do
		[ -n "$id" ] && {
			json_to_add="$(jq '.[]|select(.ID=="'"$id"'")' < "$video_json_file")"
			[ -n "$json_to_add" ] && printf '[\n%s\n]' "$json_to_add" >> "$hist_file"
		}
	done
	unset json_to_add hist_data id
}

clear_hist () {
	: > "$hist_file"
	print_info "History cleared\n"
}

#}}}

# User Interface {{{
# Takes video json file as $1 and returns the selected video IDs to file $2
video_info_text () {
	printf "%-${title_len}.${title_len}s\t" "$title"
	printf "%-${channel_len}.${channel_len}s\t" "$channel"
	printf "%-${dur_len}.${dur_len}s\t" "$duration"
	printf "%-${view_len}.${view_len}s\t" "$views"
	printf "%-${date_len}.${date_len}s\t" "$date"
	printf "%s" "$shorturl"
	printf "\n"
}

thumbnail_video_info_text () {
	[ -n "$title" ] && printf "\n ${c_cyan}%s" "$title"
	[ -n "$channel" ] && printf "\n ${c_blue}Channel  ${c_green}%s" "$channel"
	[ -n "$duration" ] && printf "\n ${c_blue}Duration ${c_yellow}%s" "$duration"
	[ -n "$views" ] && printf "\n ${c_blue}Views    ${c_magenta}%s" "$views"
	[ -n "$date" ] && printf "\n ${c_blue}Date     ${c_cyan}%s" "$date"
	[ -n "$description" ] && printf "\n ${c_blue}Description ${c_reset}: %s" "$description"
}

# Scripting interfaces {{{
interface_scripting () {
	video_json_file=$1
	selected_id_file=$2
	data_string_template='.[]|"\(.title)\t|\(.channel)\t|\(.duration)\t|\(.views)\t|\(.date)\t|\(.ID)"'
	case 1 in
		"$is_auto_select")
		jq -r "$data_string_template"  < "$video_json_file"  | head -n "$scripting_video_count" |  trim_id   > "$selected_id_file"
			;;
		"$is_random_select")
		jq -r "$data_string_template"  < "$video_json_file"  | shuf | head -n "$scripting_video_count" | trim_id > "$selected_id_file"
			;;
	esac
	# jq '.[]' < "$video_json_file" | jq -s -r --arg N "$scripting_video_count" '.[0:$N|tonumber]|.[]|.ID' > "$selected_id_file"
}
# }}}

# Text interface {{{
interface_text () {
	video_json_file=$1
	selected_id_file=$2

	# video_info_text can be set in the conf.sh, if set it will be preferred over the default given below
	TTY_COLS=$(tput cols)
	title_len=$((TTY_COLS/2))
	channel_len=$((TTY_COLS/5))
	dur_len=7
	view_len=10
	date_len=100

	jq -r '.[]|"\(.title)\t|\(.channel)\t|\(.duration)\t|\(.views)\t|\(.date)\t|\(.ID)"' < "$video_json_file" |
		sort_video_data_fn |
		while IFS=$tab_space read title channel duration views date shorturl
		do
			video_info_text
		done |
		column -t -s "$tab_space" |
		fzf -m --tabstop=1 --layout=reverse |
		trim_id > "$selected_id_file"
}
#}}}

# External interface {{{
interface_external () {
	video_json_file=$1
	selected_id_file=$2

	# video_info_text can be set in the conf.sh, if set it will be preferred over the default given below
	TTY_COLS=$external_menu_len
	title_len=$((TTY_COLS/2))
	channel_len=$((TTY_COLS/5))
	dur_len=7
	view_len=10
	date_len=100

	jq -r '.[]|"\(.title)\t|\(.channel)\t|\(.duration)\t|\(.views)\t|\(.date)\t|\(.ID)"' < "$video_json_file" |
		sort_video_data_fn |
		while IFS=$tab_space read title channel duration views date shorturl
		do
			video_info_text
		done | tr -d "$tab_space" |
		external_menu |
		trim_id > "$selected_id_file"
}
#}}}

# Thumbnail Interface {{{

# Image preview {{{
preview_start () {
	thumbnail_viewer=$1
	case $thumbnail_viewer in
		ueberzug)
			# starts uberzug to this fifo
			export UEBERZUG_FIFO="/tmp/ytfzf-ueberzug-fifo"
			rm -f "$UEBERZUG_FIFO"
			mkfifo "$UEBERZUG_FIFO"
			ueberzug layer --parser simple < "$UEBERZUG_FIFO" 2>/dev/null &
			exec 3> "$UEBERZUG_FIFO" # to keep the fifo open
			;;
	esac
}
preview_stop () {
	thumbnail_viewer=$1
	case $thumbnail_viewer in
		ueberzug)
			exec 3>&- # close file descriptor 3, closing ueberzug
			;;
	esac
}
preview_display_image () {
	thumbnail_viewer=$1
	id=$2
	case $thumbnail_viewer in
		ueberzug)
			printf '%s\t' \
				'action' 'add' \
				'identifier' 'ytfzf' \
				'path' "$thumb_dir/${id}.jpg" \
				'x' '2' \
				'y' '10' \
				'scaler' 'fit_contain' \
				'width' "$((FZF_PREVIEW_COLUMNS))" > "$UEBERZUG_FIFO"
			printf '%s\t%s\n' \
				'height' "$((FZF_PREVIEW_LINES-10))" > "$UEBERZUG_FIFO"
			;;
	esac
}
#}}}

preview_img () {
	# This function is common to every thumbnail viewer
	thumbnail_viewer=$1
	line=$2
	video_json_file=$3
	id=${line##*|}

	IFS=$tab_space read -r title channel duration views date description <<-EOF
	$(
		jq -r --arg id "$id" '.[]|select( .ID == $id )|
			[.title,.channel,.duration,.views,.date,.description]|
			@tsv' < "$video_json_file"
	)
	EOF

	thumbnail_video_info_text "$id"
	preview_display_image "$thumbnail_viewer" "$id"
}

interface_thumbnails () {
	# Takes video json file and downloads the thumnails as ${ID}.png to thumb_dir
	video_json_file=$1
	selected_id_file=$2

	# Download thumbnails, only if they're not already downloaded
	find "$thumb_dir" -type d -empty | grep -q "$thumb_dir" && {
		print_info 'Fetching thumbnails...\n'
		curl_config_file="${session_temp_dir}/curl_config"
		jq -r '.[]|"
			url = \"\(.thumbs)\"
			output = \"'"$thumb_dir"'/\(.ID).jpg\""' \
				< "$video_json_file" > "$curl_config_file"
			# curl version > 7.66.0 ( else remove -Z )
			curl -Z -K "$curl_config_file" || curl -K "$curl_config_file"
	}

	thumbnail_viewer=ueberzug

	preview_start "$thumbnail_viewer"

	# ytfzf -U preview_img ueberzug {} "$video_json_file"
	jq -r '.[]|[.title,"'"$gap_space"'|"+.channel,"|"+.duration,"|"+.views,"|"+.date,"|"+.ID]|@tsv' < "$video_json_file" |
	sort_video_data_fn |
	fzf -m \
	--preview "sh $0 -U preview_img '""$thumbnail_viewer""' {} '""$video_json_file""'" \
	--preview-window "left:50%:wrap" --layout=reverse |
	trim_id > "$selected_id_file"

	preview_stop "$thumbnail_viewer"
}
#}}}

#}}}

# Player {{{
print_requested_info () {
	set -f
	IFS=,
	for request in $info_to_print; do
	case "$request" in
	    [Ll]|link) printf '%s\n' "$@" ;;
	    VJ|vj|video-json) while read -r line; do jq '.[]|select(.ID=="'"$line"'")' < "$video_json_file"; done < "$id_file" ;;
	    [Jj]|json) jq < "$video_json_file" ;;
	    [Rr]|raw) while read -r line; do jq -r '.[]|select(.ID=="'"$line"'")|"\(.title)\t|\(.channel)\t|\(.duration)\t|\(.views)\t|\(.date)\t|\(.ID)"' < "$video_json_file"; done < "$id_file" ;;
	esac
	done
}

open_player () {
	# isaudio, isdownload, video_pref

	if [ -n "$info_to_print"  ]; then
		print_requested_info "$@"
		[ $exit_on_info_to_print -eq 1 ] && exit 0
	fi

	: ${video_pref:=best}


	if [ $is_download -eq 1 ]; then
		print_info "Downloading $# video(s)\n"
		downloader "$@"
		return
	fi

	print_info "Playing $# video(s)\n"

	if [ $is_audio_only -eq 1 ]; then
		audio_player "$@"
		return
	fi

	if [ $is_detach -eq 1 ]; then
		video_detach_player "$@"
		return
	fi

	video_player "$@"
}

player () {
	# takes the json data file as $1 and the selected id file as $2
	video_json_file=$1
	id_file=$2
	options=$3

	{
		# get urls from the ids
		urls=
		while IFS= read id || [ -n "$id" ] ; do
			# head is used so that only url is selected (a search query may have dublicates)
			urls=${urls}' '$(jq -r --arg id "$id" '.[]|select(.ID == $id).url' < "$video_json_file" | head -n 1 )
		done < "$id_file"
		[ -z "$urls" ] && return
	}

	unset IFS
	set -f
	set -- $urls
	open_player "$@"
}
#}}}

# Options {{{
parse_opt () {
	opt=$1
	optarg=$2
	#for some reason optarg may equal opt intentionally,
	#this checks the unmodified optarg, which will only be equal if there is no = sign
	[ "$opt" = "$OPTARG" ] && optarg=""
	case $opt in
		h|help) usage; exit 0 ;;
		D|external-menu) is_ext_menu=${optarg:-1}; [ $is_ext_menu -eq 1 ] && show_thumbnails=0 ;;
		m|audio-only) is_audio_only=${optarg:-1} ;;
		d|download) is_download=${optarg:-1} ;;
		f|formats) : ;; # TODO
		H|history) scrape="history" ;;
		x|history-clear) clear_hist; exit 0 ;;
		q|search-history) : ;; # TODO
		a|auto-select) is_interface_scripting=${optarg:-1}; is_auto_select=${optarg:-1} ;;
		A|select-all) is_interface_scripting=${optarg:-1}; is_auto_select=${optarg:-1}; scripting_video_count=100 ;;
		r|random-select) is_interface_scripting=${optarg:-1};is_random_select=${optarg:-1} ;; 
		n|link-count) scripting_video_count=$optarg;; 
		l|loop) is_loop=${optarg:-1} ;;
		t|show-thumbnails) show_thumbnails=${optarg:-1}; [ $show_thumbnails -eq 1 ] && is_ext_menu=0 ;;
		v) printf 'ytfzf: %s \n' "$YTFZF_VERSION"; exit 0;;
		L) info_to_print="$info_to_print,L" ;;
		pages) pages_to_scrape="$optarg" ;;
		c|scrape) scrape=$optarg ;;
		scrape+) scrape="$scrape,$optarg" ;;
		scrape-) scrape="$(printf '%s' "$scrape" | sed 's/'"$optarg"'//; s/,,/,/g')" ;;
		I) info_to_print=$optarg ;;
		#long-opt exclusives
		sort) is_sort=${optarg:-1} ;;
		video-pref) video_pref=$optarg ;;
		detach) is_detach=${optarg:-1} ;;
		ytdl-opts) ytdl_opts="$optarg" ;;
		ytdl-path) ytdl_path="$optarg" ;;
		info-print-exit) exit_on_info_to_print="${optarg:-1}" ;;
		sort-by) search_sort_by="$optarg" ;;
		upload-date) search_upload_date="$optarg" ;;
		video-duration) search_video_duration=$optarg ;;
		type) search_result_type=$optarg ;;
		features) search_result_features=$optarg ;;
		region) search_region=$optarg ;;
		channel-link) _get_real_channel_link "$optarg"; exit 0 ;;
	esac
	function_exists "on_opt_parse" && on_opt_parse "$opt" "$optarg" "$OPT" "$OPTARG"
}

while getopts "ac:dfhlmn:rtxADHI:LTU${long_opt_char}:" OPT; do
	case $OPT in
		U)
			shift $((OPTIND-1))
			case $1 in
				preview_img)
					session_cache_dir=$cache_dir/$SEARCH_PREFIX-$YTFZF_PID
					thumb_dir=$session_cache_dir/thumbnails
					shift
					preview_img "$@"
					;;
			esac
			exit 0
			;;
		"$long_opt_char")
			parse_opt "${OPTARG%%=*}" "${OPTARG#*=}" ;;
		*)
			parse_opt "${OPT}" "${OPTARG}" ;;
	esac
done
shift $((OPTIND-1))
#}}}

# Get search{{{
search="$*"
get_search () {
	case "$search" in
		-) print_info "Reading stdin\n"; read -r search ;;
		'') search_prompt_menu ;;
	esac
}
#}}}

# Sessions {{{

# each session has its own cache dir in cache_dir
# YTFZF_PID: the pid of parent
if [ -z "$YTFZF_PID" ]; then
	YTFZF_PID=$$
	SEARCH_PREFIX=$(printf "%s" "$search" | tr '/' '_')
	export YTFZF_PID
	#if no search is provided, use a fallback value of SCRAPE-$scrape
	export SEARCH_PREFIX="${SEARCH_PREFIX:-SCRAPE-$scrape}"
	session_cache_dir="${cache_dir}/${SEARCH_PREFIX}-${YTFZF_PID}"
	session_temp_dir="${session_cache_dir}/tmp"
	thumb_dir="${session_cache_dir}/thumbnails"
	mkdir -p "$session_temp_dir" "$thumb_dir"
fi

# files
: ${ytfzf_selected_ids=$session_cache_dir/ids}
: ${ytfzf_video_json_file=$session_cache_dir/videos_json}

# }}}

# Main {{{

: > "$ytfzf_video_json_file"
: > "$ytfzf_selected_ids"

handle_scrape_error () {
	case "$1" in
		6) print_error "Website unresponsive (do you have internet?)\n" ;;
	 	22) 
			case "$curr_scrape" in
				youtube|Y|youtube-trending|T)
					print_error "There was an error scraping $curr_scrape ($invidious_instance)\nTry changing invidious instances\n" ;;
				*) print_error "There was an error scraping $curr_scrape" ;;
			esac
	esac
}

scrape_website () {
	scrape_type="$1"	
	case $scrape_type in
		history|H) scrape_history "" "$ytfzf_video_json_file" ;;
		youtube|Y) 
			# youtube scrape {{{
			search_is_empty && get_search; 
			#$i is so multiple pages can be scraped
			while [ ${i:=0} -lt $pages_to_scrape ]; do
				i=$((i+1))
				scrape_invidious_search  "$search" "$ytfzf_video_json_file" "search" "$i"
				rv="$?"
				[ $rv -gt 0 ] && return "$?"
			done 
			unset i ;;
			# }}}
		youtube-trending|T) scrape_invidious_trending  "$search" "$ytfzf_video_json_file" "trending";;
		youtube-subscriptions|S|SI)#{{{
		    ! [ -f "$YTFZF_SUBSCRIPTIONS_FILE" ] && die 2 "subscriptions file doesn't exist\n"

		    [ "$scrape_type" = "SI" ] && channel_scraper="scrape_invidious_channel" || channel_scraper="scrape_youtube_channel"

		    #if _tmp_subfile does not have a unique name, weird things happen
		    i=0
		    while IFS= read channel_url || [ -n "$channel_url" ] ; do
			    i=$((i+1))
			    {
				    _tmp_subfile="${session_temp_dir}/channel-$i"
				    $channel_scraper "$channel_url" "$_tmp_subfile" "channel-$i" < /dev/null
				    rv="$?"
				    [ $rv -gt 0 ] && return "$rv"
				    jq '.[0:'"$sub_link_count"']' < "$_tmp_subfile" >> "$ytfzf_video_json_file"
			    } &
			    sleep 0.01
		    done <<- EOF
			$(sed \
				-e "s/#.*//" \
				-e "/^[[:space:]]*$/d" \
				-e "s/[[:space:]]*//g" \
				"$YTFZF_SUBSCRIPTIONS_FILE" )
			EOF
		    wait
		    ;;#}}}
		peertube|P) search_is_empty && get_search; scrape_peertube "$search" "$ytfzf_video_json_file" ;;
		odysee|lbry|O) search_is_empty && get_search; scrape_odysee "$search" "$ytfzf_video_json_file" ;;
		*) die 2 "invalid scraper: $scrape_type\n" ;;
	esac
	rv="$?"
	unset scrape_type
	return $rv
}

IFS=","
set -f
for curr_scrape in $scrape; do
	scrape_website "$curr_scrape"
	handle_scrape_error "$?"
done

[ ! -s "$ytfzf_video_json_file" ] && die 4 "Nothing was scraped\n"

while :; do
	case 1 in
		 "$is_interface_scripting") interface_scripting "$ytfzf_video_json_file" "$ytfzf_selected_ids" ;;
		"$show_thumbnails") interface_thumbnails "$ytfzf_video_json_file" "$ytfzf_selected_ids" ;;
		    "$is_ext_menu") interface_external   "$ytfzf_video_json_file" "$ytfzf_selected_ids" ;;
				 1) interface_text       "$ytfzf_video_json_file" "$ytfzf_selected_ids" ;;
	esac
	[ $enable_hist -eq 1 ] && add_to_hist < "$ytfzf_selected_ids"

	player "$ytfzf_video_json_file" "$ytfzf_selected_ids"
	[ $is_loop -eq 0 ] || [ ! -s "$ytfzf_selected_ids" ] && break
done
#}}}

# vim:foldmethod=marker
